{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza.download('en')\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,lemma',  verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize(data):\n",
    "    \"\"\"Tokenize words\n",
    "    Inputs:\n",
    "        data : str\n",
    "            A string containing the article text\n",
    "    Outputs:\n",
    "        out : list\n",
    "            List of tokenized and lemmatized words\n",
    "    \"\"\"\n",
    "    nlp = stanza.Pipeline(lang='en', processors='tokenize,lemma',  verbose=False)\n",
    "    doc = nlp(data)\n",
    "    out = []\n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            out.append(word.lemma.lower())\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder_name, max_words):\n",
    "    '''\n",
    "    Loads title and text from the given folder and stores it to a numpy array. Takes max_words amount of words from the text\n",
    "    \n",
    "    Inputs:\n",
    "    folder_name : str\n",
    "        destination of csv file\n",
    "    max_words : int\n",
    "        number of words to take from text\n",
    "        \n",
    "    Outputs:\n",
    "    ret : numpy array\n",
    "        shape(N,2), where first column is title and second is corresponding text\n",
    "    '''\n",
    "    df = pd.read_csv(folder_name)\n",
    "    df = df[['title', 'content']].copy()\n",
    "    df = df.dropna()\n",
    "    titles = df['title'].apply(lambda x: x.lower() )\n",
    "    text = df['content'].apply(lambda x: \" \".join(x.split()[0:max_words]).lower() )\n",
    "    ret = np.array([titles, text]).T\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file, max_words):\n",
    "    ''' \n",
    "    Main function for extracting data\n",
    "    \n",
    "    Inputs:\n",
    "    file : str\n",
    "        destination of csv file\n",
    "    max_words : int\n",
    "        number of words to take from text\n",
    "    \n",
    "    Outputs:\n",
    "    data1: numpy array\n",
    "        An array of shape (N,2), where on each row there is a tokenized and lemmatized title of the article and a 50 word long\n",
    "        tokenized and lemmatized text.\n",
    "    '''\n",
    "    data1 = load_data(file, max_words)\n",
    "    \n",
    "    for i in range(data1.shape[0]):\n",
    "        data1[i,0] = tokenize(data1[i,0])\n",
    "        data1[i,1] = tokenize(data1[i,1])\n",
    "        if i%1000 == 0:\n",
    "            print(i)\n",
    "            print(time.time()-start)\n",
    "    \n",
    "    return data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make data suitable for BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = load_data('data/articles1.csv', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['house republicans fret about winning their health care suit - the new york times',\n",
       "        'washington — congressional republicans have a new fear when it comes to their health care lawsuit against the obama administration: they might win. the incoming trump administration could choose to no longer defend the executive branch against the suit, which challenges the administration’s authority to spend billions of dollars on'],\n",
       "       ['rift between officers and residents as killings persist in south bronx - the new york times',\n",
       "        'after the bullet shells get counted, the blood dries and the votive candles burn out, people peer down from windows and see crime scenes gone cold: a band of yellow police tape blowing in the breeze. the south bronx, just across the harlem river from manhattan and once shorthand for'],\n",
       "       ['tyrus wong, ‘bambi’ artist thwarted by racial bias, dies at 106 - the new york times',\n",
       "        'when walt disney’s “bambi” opened in 1942, critics praised its spare, haunting visual style, vastly different from anything disney had done before. but what they did not know was that the film’s striking appearance had been created by a chinese immigrant artist, who took as his inspiration the landscape paintings'],\n",
       "       ...,\n",
       "       ['trump announces plan that does little to resolve his conflicts of interest',\n",
       "        'donald trump will not be taking necessary steps to resolve his conflicts of interest before he takes office. at his press conference today — his first since june 2016 — trump and his lawyer sheri dillon laid out the plans that they claimed would resolve the questions about conflicts of'],\n",
       "       ['dozens of for-profit colleges could soon close ',\n",
       "        'dozens of colleges could be forced to close in the next several years. this week, the obama administration published a list of schools and programs that are at risk of losing access to the federal loans many of them depend on to survive. more than 800 vocational programs the department'],\n",
       "       ['the milky way’s stolen stars',\n",
       "        'the force of gravity can be described using a number of metaphors: it’s the glue that holds solar systems and galaxies together, the anchor that keeps us on the ground, the slingshot that sends spacecraft deeper into the solar system. and in some cases, gravity is a thief. astronomers at']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = load_data('data/articles2.csv', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = load_data('data/articles3.csv', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((data1,data2,data3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142568, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/articles_comb.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cells for running extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takes about 1.5 hours each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "#extract = extract_data('data/articles1.csv',50)\n",
    "#np.save('data/extracted1.npy', extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "#extract = extract_data('data/articles2.csv',50)\n",
    "#np.save('data/extracted2.npy', extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "#extract = extract_data('data/articles3.csv',50)\n",
    "#np.save('data/extracted3.npy', extract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the tokenized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopo1 = np.load('data/extracted1.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopo2 = np.load('data/extracted2.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopo3 = np.load('data/extracted3.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "hopo_combined = np.concatenate((hopo1,hopo2,hopo3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142568, 2)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hopo_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/extracted_comb.npy', hopo_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
